{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from PIL import Image\n",
    "import clip\n",
    "import torch\n",
    "import skimage as sk #image processing library\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image #image processing library\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# splitting the dataset into training and testing 80:20\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read & Split the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Cats&Dogs_Dataset.csv\")\n",
    "\n",
    "# only rows in image column that contain string with cat\n",
    "df_cat = df[df[\"image\"].str.contains(\"cat\")]\n",
    "# only rows in image column that contain string with dog\n",
    "df_dog = df[df[\"image\"].str.contains(\"dog\")]\n",
    "\n",
    "# train test split\n",
    "train_cat, test_cat = train_test_split(df_cat, test_size=0.2, random_state=1)\n",
    "train_dog, test_dog = train_test_split(df_dog, test_size=0.2, random_state=1)\n",
    "\n",
    "#take only 10 rows from each dataset to train the model\n",
    "train_cat = train_cat.head(50)\n",
    "train_dog = train_dog.head(50)\n",
    "\n",
    "test_cat = test_cat.head(50)\n",
    "test_dog = test_dog.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Clip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model once at the beginning\n",
    "# model, preprocess = clip.load(\"ViT-B/32\", device=\"cpu\") \n",
    "# model.eval() # move model to GPU and set it to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model , preprocess = clip.load(\"ViT-B/32\", device=\"cpu\") #we chose this model because it is the smallest one and it is the fastest one to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up input images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# images destination\n",
    "descriptions = {\n",
    "\"C\",\n",
    "\"D\",\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_images = []\n",
    "processed_images = []\n",
    "descriptions = [\"Cat\", \"Dog\"]  # Change set to list\n",
    "plt.figure(figsize=(16, 16))\n",
    "\n",
    "# preprocess the images\n",
    "for i in range(0, 8):\n",
    "    var = ''\n",
    "    if i % 2 == 0: \n",
    "        var = 'cat.' + str(i) \n",
    "    else:\n",
    "        var = 'dog.' + str(i)\n",
    "    # original image\n",
    "    original_image = Image.open('./Cats&Dogs_Pics/' + var + '.jpg')\n",
    "    original_images.append(original_image)\n",
    "    # processed image\n",
    "    processed_image = preprocess(original_image)\n",
    "    processed_images.append(processed_image)\n",
    "    # description\n",
    "    plt.subplot(1, 8, i + 1)\n",
    "    plt.imshow(original_image)\n",
    "    if i % 2 == 0:\n",
    "        plt.title(descriptions[0])\n",
    "    else:\n",
    "        plt.title(descriptions[1])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building Features\n",
    "image_input_train_cat = torch.stack([preprocess(Image.open('./Cats&Dogs_Pics/' + img_path)) for img_path in train_cat['image']]) #preprocess the images and stack them into a tensor\n",
    "image_input_train_dog = torch.stack([preprocess(Image.open('./Cats&Dogs_Pics/' + img_path)) for img_path in train_dog['image']]) #preprocess the images and stack them into a tensor\n",
    "\n",
    "text_tokens_train_cat = clip.tokenize(descriptions[0] * len(train_cat)) #tokenize the text and stack them into a tensor\n",
    "text_tokens_train_dog = clip.tokenize(descriptions[1] * len(train_dog)) #tokenize the text and stack them into a tensor\n",
    "\n",
    "text_features_train_cat = model.encode_text(text_tokens_train_cat).float() #encode the text and convert to float\n",
    "text_features_train_dog = model.encode_text(text_tokens_train_dog).float() #encode the text and convert to float\n",
    "\n",
    "# Combine image and text features\n",
    "with torch.no_grad(): #disable gradient calculation to speed up computation and reduce memory consumption\n",
    "    image_features_train_cat = model.encode_image(image_input_train_cat).float()\n",
    "    image_features_train_dog = model.encode_image(image_input_train_dog).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test data\n",
    "image_input_test_cat = torch.stack([preprocess(Image.open('./Cats&Dogs_Pics/' + img_path)) for img_path in test_cat['image']]) #preprocess the images and stack them into a tensor\n",
    "image_input_test_dog = torch.stack([preprocess(Image.open('./Cats&Dogs_Pics/' + img_path)) for img_path in test_dog['image']]) #preprocess the images and stack them into a tensor\n",
    "\n",
    "text_tokens_test_cat = clip.tokenize(descriptions[0] * len(test_cat)) #tokenize the text and stack them into a tensor\n",
    "text_tokens_test_dog = clip.tokenize(descriptions[1] * len(test_dog)) #tokenize the text and stack them into a tensor\n",
    "\n",
    "text_features_test_cat = model.encode_text(text_tokens_test_cat).float() #encode the text and convert to float\n",
    "text_features_test_dog = model.encode_text(text_tokens_test_dog).float() #encode the text and convert to float\n",
    "\n",
    "# Combine image and text features\n",
    "with torch.no_grad(): #disable gradient calculation to speed up computation and reduce memory consumption\n",
    "    image_features_test_cat = model.encode_image(image_input_test_cat).float()\n",
    "    image_features_test_dog = model.encode_image(image_input_test_dog).float()\n",
    "\n",
    "text_features_test_cat.type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_and_visualize_combined_cosine_similarity(image_features_cat, text_features_cat, image_features_dog, text_features_dog, descriptions, original_images):\n",
    "    # Normalize the features\n",
    "    image_features_cat /= image_features_cat.norm(dim=-1, keepdim=True)\n",
    "    text_features_cat /= text_features_cat.norm(dim=-1, keepdim=True)\n",
    "    image_features_dog /= image_features_dog.norm(dim=-1, keepdim=True)\n",
    "    text_features_dog /= text_features_dog.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    # Calculate cosine similarity for both cats and dogs\n",
    "    similarity_matrix_cat = text_features_cat.detach().numpy() @ image_features_cat.detach().numpy().T\n",
    "    similarity_matrix_dog = text_features_dog.detach().numpy() @ image_features_dog.detach().numpy().T\n",
    "\n",
    "    # Create a combined visualization\n",
    "    count_cat = len(descriptions[0])\n",
    "    count_dog = len(descriptions[1])\n",
    "\n",
    "    plt.figure(figsize=(20, 14))\n",
    "\n",
    "    # Plot Cat Images\n",
    "    plt.subplot(2, 2, 1)\n",
    "    for i, image in enumerate(original_images[:count_cat]):\n",
    "        plt.imshow(image, extent=(i - 0.5, i + 0.5, -0.6, 0.6), origin=\"upper\")  # Adjust extent and origin\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.title(\"Original Images - Cats\", size=20)\n",
    "\n",
    "    for side in [\"left\", \"top\", \"right\", \"bottom\"]:\n",
    "        plt.gca().spines[side].set_visible(False)\n",
    "\n",
    "    # Plot Cosine Similarity Matrix for Cats\n",
    "    plt.subplot(2, 2, 2)\n",
    "    plt.imshow(similarity_matrix_cat, vmin=0.1, vmax=0.3, cmap='viridis', origin=\"upper\")  # Adjust origin\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.title(\"Cosine Similarity Matrix - Cats\", size=20)\n",
    "\n",
    "    for x in range(similarity_matrix_cat.shape[1]):\n",
    "        for y in range(similarity_matrix_cat.shape[0]):\n",
    "            plt.text(x, y, f\"{similarity_matrix_cat[y, x]:.2f}\", ha=\"center\", va=\"center\", size=12)\n",
    "\n",
    "    for side in [\"left\", \"top\", \"right\", \"bottom\"]:\n",
    "        plt.gca().spines[side].set_visible(False)\n",
    "\n",
    "    # Plot Dog Images\n",
    "    plt.subplot(2, 2, 3)\n",
    "    for i, image in enumerate(original_images[count_cat:count_cat + count_dog]):\n",
    "        plt.imshow(image, extent=(i - 0.5, i + 0.5, -0.6, 0.6), origin=\"upper\")  # Adjust extent and origin\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.title(\"Original Images - Dogs\", size=20)\n",
    "\n",
    "    for side in [\"left\", \"top\", \"right\", \"bottom\"]:\n",
    "        plt.gca().spines[side].set_visible(False)\n",
    "\n",
    "    # Plot Cosine Similarity Matrix for Dogs\n",
    "    plt.subplot(2, 2, 4)\n",
    "    plt.imshow(similarity_matrix_dog, vmin=0.1, vmax=0.3, cmap='viridis', origin=\"upper\")  # Adjust origin\n",
    "    plt.yticks([])\n",
    "    plt.xticks([])\n",
    "    plt.title(\"Cosine Similarity Matrix - Dogs\", size=20)\n",
    "\n",
    "    for x in range(similarity_matrix_dog.shape[1]):\n",
    "        for y in range(similarity_matrix_dog.shape[0]):\n",
    "            plt.text(x, y, f\"{similarity_matrix_dog[y, x]:.2f}\", ha=\"center\", va=\"center\", size=12)\n",
    "\n",
    "    for side in [\"left\", \"top\", \"right\", \"bottom\"]:\n",
    "        plt.gca().spines[side].set_visible(False)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Visualize Combined Cosine Similarity Matrix for Cats and Dogs\n",
    "calculate_and_visualize_combined_cosine_similarity(image_features_train_cat, text_features_train_cat, image_features_train_dog, text_features_train_dog, descriptions, original_images)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fisher's Algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_cat = torch.mean(image_features_train_cat, dim=0)  # Calculate mean for cat features\n",
    "mean_dog = torch.mean(image_features_train_dog, dim=0)  # Calculate mean for dog features\n",
    "\n",
    "# scatter matrices for cats and dogs\n",
    "scatter_cat = torch.matmul((image_features_train_cat - mean_cat).T, (image_features_train_cat - mean_cat))\n",
    "scatter_dog = torch.matmul((image_features_train_dog - mean_dog).T, (image_features_train_dog - mean_dog))\n",
    "\n",
    "# The whole baa class scatter matrix (Sw)\n",
    "Sw = scatter_cat + scatter_dog\n",
    "\n",
    "C_values = [0.1, 1, 10]  # Different values of C to try\n",
    "best_accuracy = 0\n",
    "best_C = None\n",
    "\n",
    "for C in C_values:\n",
    "    sInv = torch.inverse(Sw)\n",
    "    w = C * torch.matmul(sInv, (mean_dog - mean_cat))\n",
    "    \n",
    "    # Combining test& train features and labels\n",
    "    test_features = torch.cat((image_features_test_cat, image_features_test_dog), dim=0)\n",
    "    test_labels = torch.cat((torch.zeros(len(test_cat)), torch.ones(len(test_dog))), dim=0)  # 0 for cats, 1 for dogs\n",
    "    train_features = torch.cat((image_features_train_cat, image_features_train_dog), dim=0)\n",
    "    train_labels = torch.cat((torch.zeros(len(train_cat)), torch.ones(len(train_dog))), dim=0)  # 0 for cats, 1 for dogs\n",
    "\n",
    "    # Perform hyperparameter tuning\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300], #number of trees in the forest\n",
    "        'max_depth': [None, 10, 20], #maximum depth of the tree\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(RandomForestClassifier(), param_grid, cv=5) #GridSearchCV performs hyperparameter tuning\n",
    "    grid_search.fit(train_features, train_labels) #fit the model\n",
    "\n",
    "    best_params = grid_search.best_params_ \n",
    "    \n",
    "    # Re-train your model using the best parameters\n",
    "    best_model = RandomForestClassifier(n_estimators=best_params['n_estimators'], max_depth=best_params['max_depth'])\n",
    "    best_model.fit(train_features, train_labels)\n",
    "\n",
    "    # Make predictions\n",
    "    threshold = 0.6  \n",
    "    predicted_probability = best_model.predict_proba(test_features)\n",
    "    predicted = (predicted_probability[:, 1] >= threshold).astype(int)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(test_labels, predicted)\n",
    "\n",
    "    # Check if this value of C gives a higher accuracy\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_C = C\n",
    "\n",
    "print(f\"Best C value: {best_C} with Accuracy: {best_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "conf_matrix = confusion_matrix(test_labels, predicted)\n",
    "accuracy = accuracy_score(test_labels, predicted)\n",
    "precision = precision_score(test_labels, predicted)\n",
    "recall = recall_score(test_labels, predicted)\n",
    "f1 = f1_score(test_labels, predicted)\n",
    "\n",
    "print(f\"Accuracy: {best_accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the confusion matrix\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(conf_matrix, annot=True, cmap='Blues', fmt='d', cbar=False)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
